{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.miscellaneous import get_pareto_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['grid.color'] = 'k'\n",
    "mpl.rcParams['grid.linestyle'] = ':'\n",
    "mpl.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [7, 5]\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 'small'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "figures_folder = 'results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto-front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MSGNN = pd.read_csv('results/Pareto_front/overview_MSGNN.csv')\n",
    "df_GNN = pd.read_csv('results/Pareto_front/overview_GNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(14,5), gridspec_kw={'width_ratios': [1, 1.2]})\n",
    "\n",
    "cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "\n",
    "# RMSE\n",
    "axs[0].scatter(df_GNN['val_loss'], df_GNN[f'speed-up'], c=df_GNN['total parameters'], \n",
    "               norm=mpl.colors.LogNorm(vmin=1e4, vmax=1e6), cmap=cmap, marker='x')\n",
    "\n",
    "axs[0].scatter(df_MSGNN['val_loss'], df_MSGNN[f'speed-up'], c=df_MSGNN['total parameters'], \n",
    "               norm=mpl.colors.LogNorm(vmin=1e4, vmax=1e6), cmap=cmap, marker='o')\n",
    "\n",
    "\n",
    "pareto_front = get_pareto_front(df_GNN, 'val_loss', 'speed-up', ascending=True)\n",
    "axs[0].plot(pareto_front[:,0], pareto_front[:,1], 'r--', linewidth=1, marker='')\n",
    "\n",
    "pareto_front = get_pareto_front(df_MSGNN, 'val_loss', 'speed-up', ascending=True)\n",
    "axs[0].plot(pareto_front[:,0], pareto_front[:,1], 'r--', linewidth=1, marker='')\n",
    "\n",
    "\n",
    "\n",
    "# CSI\n",
    "axs[1].scatter(df_GNN['val_CSI_005'], df_GNN[f'speed-up'], c=df_GNN['total parameters'], \n",
    "               norm=mpl.colors.LogNorm(vmin=1e4, vmax=1e6), cmap=cmap, marker='x')\n",
    "\n",
    "scat = axs[1].scatter(df_MSGNN['val_CSI_005'], df_MSGNN[f'speed-up'], c=df_MSGNN['total parameters'], \n",
    "               norm=mpl.colors.LogNorm(vmin=1e4, vmax=1e6), cmap=cmap, marker='o')\n",
    "\n",
    "pareto_front = get_pareto_front(df_GNN, 'speed-up', 'val_CSI_005', ascending=False)\n",
    "axs[1].plot(pareto_front[:,1], pareto_front[:,0], 'r--', linewidth=1, marker='')\n",
    "\n",
    "pareto_front = get_pareto_front(df_MSGNN, 'speed-up', 'val_CSI_005', ascending=False)\n",
    "axs[1].plot(pareto_front[:,1], pareto_front[:,0], 'r--', linewidth=1, marker='')\n",
    "\n",
    "clb = plt.colorbar(scat, ax=axs[1])\n",
    "clb.set_label('N parameters')\n",
    "clb.set_ticks([1e4, 1e5, 1e6])\n",
    "\n",
    "axs[1].scatter(x=[], y=[], c='k', marker='o', label='mSWE-GNN')\n",
    "axs[1].scatter(x=[], y=[], c='k', marker='x', label='SWE-GNN')\n",
    "axs[0].set_xlabel('Val RMSE')\n",
    "axs[0].set_ylabel('Speed-up')\n",
    "axs[1].set_xlabel('Val CSI$_{0.05m}$')\n",
    "axs[1].legend(title='Model', loc='upper left')\n",
    "axs[0].spines[['right','top']].set_visible(False)\n",
    "axs[1].spines[['right','top']].set_visible(False)\n",
    "axs[0].set_ylim(0,1400)\n",
    "axs[1].set_ylim(0,1400)\n",
    "axs[1].set_xlim(0.45,0.9)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass conservation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/mass_conservation.csv')\n",
    "# df = df.drop(9)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(13,5))\n",
    "\n",
    "# loss\n",
    "axs[0].scatter(df['trainer_options.conservation']*1e-6, df['val_loss'])\n",
    "axs[0].set_xlabel(r'$\\alpha_M$')\n",
    "axs[0].set_ylabel('Validation loss')\n",
    "\n",
    "\n",
    "# CSI\n",
    "axs[1].scatter(df['trainer_options.conservation']*1e-6, df['val_CSI_005'])\n",
    "axs[1].set_xlabel(r'$\\alpha_M$')\n",
    "axs[1].set_ylabel(r'Validation CSI$_{0.05}$')\n",
    "\n",
    "\n",
    "axs[0].spines[['right','top']].set_visible(False)\n",
    "axs[1].spines[['right','top']].set_visible(False)\n",
    "axs[0].set_xscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "\n",
    "# use scientific notation for y-axis\n",
    "axs[0].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print('Loss:', pearsonr(df['trainer_options.conservation'], df['val_loss']))\n",
    "print('CSI:', pearsonr(df['trainer_options.conservation'], df['val_CSI_005']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/batch_prediction_times.csv')\n",
    "grouped_df = df.groupby('num_parameters')\n",
    "\n",
    "from utils.miscellaneous import get_numerical_times\n",
    "\n",
    "numerical_times = get_numerical_times('multiscale_mesh_dataset_test', \n",
    "                                      20, 120, 48, time_start=0, time_stop=-1, \n",
    "                                      overview_file='database/overview.csv')\n",
    "\n",
    "cmap=sns.cubehelix_palette(as_cmap=True)\n",
    "norm = mpl.colors.LogNorm(vmin=4.8e4, vmax=4.8e5)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "for name, group in grouped_df:\n",
    "    ax.plot(group['batch_size'], numerical_times.sum()/group['prediction_times'], '-', c=cmap(norm(group['num_parameters'].values[0])))\n",
    "    ax.scatter(group['batch_size'], numerical_times.sum()/group['prediction_times'], s=3+2.5**group['K'].values[0], color=cmap(norm(group['num_parameters'].values[0])))\n",
    "\n",
    "# add legend\n",
    "for i in range(2,6):\n",
    "    ax.scatter([], [], s=3+2.5**i, color='k', label=f'{i}')\n",
    "ax.legend(title='GNN layers\\n  per scale', fontsize='xx-small')\n",
    "\n",
    "ax.set_xlabel('Batch Size')\n",
    "ax.set_ylabel('Speed-up')\n",
    "\n",
    "ax.set_xscale('log', base=2)\n",
    "xlabel = [1, 2, 4, 8, 16]\n",
    "ax.set_xticks(xlabel, xlabel)\n",
    "\n",
    "ax.set_yscale('log', base=2)\n",
    "ylabel = [50, 100, 200, 400, 800]\n",
    "ax.set_yticks(ylabel, ylabel)\n",
    "\n",
    "# add colorbar with discrete ticks\n",
    "clb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax)\n",
    "clb.set_label('N parameters')\n",
    "# clb.set_ticks([1e4, 1e5, 1e6])\n",
    "\n",
    "# Average speed-up by batching (compare 20 to 1 batch size)\n",
    "batching_speedup = (df.iloc[::6].prediction_times.values / df.iloc[5::6].prediction_times.values).mean()\n",
    "print(f'Average speed-up by batching: {batching_speedup:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 381\n",
    "train_dataset = load_dataset('mesh_dataset', 80, seed, os.path.join('database/datasets', 'train'))\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.25, random_state=seed)\n",
    "test_dataset = load_dataset('mesh_dataset', 20, seed=0, dataset_folder=os.path.join('database/datasets', 'test'))\n",
    "test_dataset2 = load_dataset('dijkring_15_fine', 10, seed=0, dataset_folder=os.path.join('database/datasets', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DEM\", \"Num_cells\", \"Area\", \"Edge length\", \"Total volume\")\n",
    "dataset_names = ['Train', 'Validation', 'Test', 'Test2']\n",
    "for i, dataset in enumerate([train_dataset, val_dataset, test_dataset, test_dataset2]):\n",
    "    DEM = torch.cat([i.DEM for i in dataset])\n",
    "    num_cells = np.array([i.num_nodes for i in dataset])\n",
    "    area = torch.cat([i.area for i in dataset])\n",
    "    edge_length = np.concatenate([i.mesh.edge_length for i in dataset])\n",
    "    total_volume = np.array([(i.WD[:,-1]*i.area).sum() for i in dataset])/10e6\n",
    "\n",
    "    print(dataset_names[i], '&',\n",
    "          round(DEM.mean().item(), 2), '$\\pm$', round(DEM.std().item(), 2), '&',\n",
    "            round(num_cells.mean()), '$\\pm$', round(num_cells.std()), '&',\n",
    "            round(area.mean().item()), '$\\pm$', round(area.std().item()), '&',\n",
    "            round(edge_length.mean(), 1), '$\\pm$', round(edge_length.std(), 1), '&',\n",
    "            round(total_volume.mean().item(), 2), '$\\pm$', round(total_volume.std().item(), 2), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import plot_line_with_deviation\n",
    "\n",
    "hydrograph_mesh_path = 'database/raw_datasets_mesh/Hydrograph'\n",
    "hydrograph_dike_path = 'database/raw_datasets_dk15/Hydrograph'\n",
    "\n",
    "train_hydrograph = np.array([np.loadtxt(os.path.join(hydrograph_mesh_path, f'Hydrograph_{i}.txt')) for i in range(1,80)])\n",
    "test_hydrograph = np.array([np.loadtxt(os.path.join(hydrograph_mesh_path, f'Hydrograph_{i}.txt')) for i in range(81,100)])\n",
    "dike_hydrograph = np.array([np.loadtxt(os.path.join(hydrograph_dike_path, f'Hydrograph_{i}.txt')) for i in range(101,112)])\n",
    "\n",
    "time_vector = train_hydrograph[0][::2,0]/3600\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "plot_line_with_deviation(time_vector, train_hydrograph[:,::2,1], with_minmax=True, ax=ax, label='Train')\n",
    "plot_line_with_deviation(time_vector, test_hydrograph[:,::2,1], with_minmax=True, ax=ax, label='Test')\n",
    "plot_line_with_deviation(time_vector, dike_hydrograph[:,::2,1], with_minmax=True, ax=ax, label='Test dike ring 15')\n",
    "\n",
    "ax.set_xlabel('Time [h]')\n",
    "ax.set_ylabel('Discharge [$m^3$/s]')\n",
    "ax.legend(loc=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "751ff9f3dce1395adb2e3795e68eeeed688a6558fa29bf9be6c36716ccf55324"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
